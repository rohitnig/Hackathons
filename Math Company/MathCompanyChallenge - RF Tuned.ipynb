{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test  = pd.read_csv('test.csv')\n",
    "train.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['logPrice'] = np.log(train.Price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.displot(train.logPrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowPrice = np.quantile(train.logPrice, 0.02)\n",
    "highPrice = np.quantile(train.logPrice, 0.99)\n",
    "print (lowPrice, highPrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['cappedLogPrice'] = train.logPrice\n",
    "train.loc[train.logPrice < lowPrice, 'cappedLogPrice'] = lowPrice\n",
    "train.loc[train.logPrice > highPrice, 'cappedLogPrice'] = highPrice\n",
    "sns.histplot(train.cappedLogPrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(train.cappedLogPrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train.drop(columns=['ID', 'Price', 'logPrice'])\n",
    "df_train.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Manufacturer', 'Category', 'Leather interior', 'Fuel type',\n",
    "           'Gear box type', 'Drive wheels', 'Doors', 'Wheel', 'Color']\n",
    "num_cols = ['Levy', 'Prod. year', 'Engine volume', \n",
    "            'Airbags', 'Cylinders', 'Mileage']\n",
    "print (len(df_train.columns.to_list()), \n",
    "        len(cat_cols),\n",
    "        len(num_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(train.Doors.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_manufacturers = df_train.Manufacturer.value_counts().head(20).reset_index()['index'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mileage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[df_train.Levy=='-', 'Levy'] = 0\n",
    "df_train.Mileage = train.Mileage.apply(lambda x: int(x[:-3]))\n",
    "df_train.loc[df_train.Mileage==0, 'Mileage'] = None\n",
    "df_train['Mileage'] = df_train['Mileage'].\\\n",
    "                        fillna(df_train.groupby('Prod. year')['Mileage'].transform('median'))\n",
    "df_train.Mileage.fillna(df_train.Mileage.mean(), inplace=True)\n",
    "df_train.Mileage = np.log(df_train.Mileage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[num_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.Levy = df_train.Levy.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Engine volume'] = df_train['Engine volume'].apply(lambda x: float(x.split(' ')[0]))\n",
    "df_train['Engine volume'] = df_train['Engine volume'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[~df_train.Manufacturer.isin(top_manufacturers), 'Manufacturer'] = 'Other'\n",
    "for col in cat_cols:\n",
    "    print (col, ': ', len(df_train[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df_train[cat_cols], drop_first=True)\n",
    "df_dummies.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = pd.concat([df_train[num_cols], df_dummies], axis=1)\n",
    "y = df_train.cappedLogPrice\n",
    "X_cols = X.columns.to_list()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[X_cols], y, test_size = 0.2, random_state = 42)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_cols)\n",
    "X_test_scaled  = pd.DataFrame(scaler.transform(X_test), columns=X_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 4))\n",
    "sns.boxplot(y='Mileage', x='Prod. year', data=X_train)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null = pd.DataFrame(X_train.isna().sum()).reset_index()\n",
    "df_null.columns = ['Feature', 'isNull']\n",
    "df_null.sort_values(by='isNull').tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#rf_model = RandomForestRegressor(oob_score=True, random_state=42).fit(X_train_scaled, y_train)\n",
    "#rf_model.score(X_test_scaled, y_test)                              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pprint import pprint\n",
    "#from sklearn.model_selection import RandomizedSearchCV\n",
    "#\n",
    "## Number of trees in random forest\n",
    "#n_estimators = [int(x) for x in np.linspace(start = 200, stop = 100, num = 10)]\n",
    "## Number of features to consider at every split\n",
    "#max_features = ['auto', 'sqrt']\n",
    "## Maximum number of levels in tree\n",
    "#max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "#max_depth.append(None)\n",
    "## Minimum number of samples required to split a node\n",
    "#min_samples_split = [2, 5, 10]\n",
    "## Minimum number of samples required at each leaf node\n",
    "#min_samples_leaf = [1, 2, 4]\n",
    "## Method of selecting samples for training each tree\n",
    "#bootstrap = [True, False]# Create the random grid\n",
    "#random_grid = {'n_estimators': n_estimators,\n",
    "#               'max_features': max_features,\n",
    "#               'max_depth': max_depth,\n",
    "#               'min_samples_split': min_samples_split,\n",
    "#               'min_samples_leaf': min_samples_leaf,\n",
    "#               'bootstrap': bootstrap}\n",
    "#pprint(random_grid)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_random = RandomizedSearchCV(estimator = RandomForestRegressor(), \n",
    "#                               param_distributions = random_grid, \n",
    "#                               n_iter = 100, cv = 3, verbose=2, random_state=42, \n",
    "#                               n_jobs = -1)# Fit the random search model\n",
    "#\n",
    "#rf_random.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_random.best_estimator_.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_tuned = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best = RandomForestRegressor(bootstrap=False, max_depth=80, max_features='sqrt',\n",
    "                      min_samples_split=5, n_estimators=133).fit(X_train_scaled, y_train)\n",
    "rf_best.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "np.sqrt(mean_squared_log_error(\n",
    "        np.exp(y_test), \n",
    "        np.exp(rf_best.predict(X_test_scaled))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importance = pd.DataFrame(rf_best.feature_importances_, columns = ['Importance'])\n",
    "df_importance['Feature'] = X_cols\n",
    "df_importance = df_importance[['Feature', 'Importance']].sort_values(by='Importance', ascending=False)\n",
    "sns.barplot(x='Importance', y='Feature', data=df_importance.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.svm import SVR\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "\n",
    "stack_gen = StackingRegressor(regressors=(CatBoostRegressor(verbose=0),\n",
    "                                          KNeighborsRegressor(),\n",
    "                                          LGBMRegressor(),\n",
    "                                          SVR()),\n",
    "                              meta_regressor = CatBoostRegressor(),\n",
    "                              use_features_in_secondary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model = stack_gen.fit(X_train_scaled, y_train)\n",
    "stack_model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_model.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool\n",
    "\n",
    "train_data = Pool(X_train_scaled)\n",
    "\n",
    "cat_model = CatBoostRegressor(verbose=0).fit(X_train_scaled, y_train)\n",
    "interaction = cat_model.get_feature_importance(train_data, type=\"Interaction\")\n",
    "column_names = X_train_scaled.columns.values \n",
    "interaction = pd.DataFrame(interaction, columns=[\"feature1\", \"feature2\", \"importance\"])\n",
    "interaction.feature1 = interaction.feature1.apply(lambda l: column_names[int(l)])\n",
    "interaction.feature2 = interaction.feature2.apply(lambda l: column_names[int(l)])\n",
    "interaction.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = test.drop(columns = 'ID')\n",
    "\n",
    "df_test.loc[df_test.Levy=='-', 'Levy'] = 0\n",
    "df_test.loc[df_test.Doors=='04-May', 'Doors'] = '4-May'\n",
    "df_test.loc[df_test.Doors=='02-Mar', 'Doors'] = '2-Mar'\n",
    "\n",
    "df_test.Mileage = df_test.Mileage.apply(lambda x: int(x[:-3]))\n",
    "df_test.loc[df_test.Mileage==0, 'Mileage'] = None\n",
    "df_test['Mileage'] = df_test['Mileage'].\\\n",
    "                        fillna(df_test.groupby('Prod. year')['Mileage'].transform('median'))\n",
    "df_test.Mileage.fillna(df_test.Mileage.mean(), inplace=True)\n",
    "df_test.Mileage = np.log(df_test.Mileage)\n",
    "\n",
    "df_test['Engine volume'].apply(lambda x: float(x.split(' ')[0]))\n",
    "df_test['Engine volume'] = df_test['Engine volume'].apply(lambda x: float(x.split(' ')[0]))\n",
    "\n",
    "df_test.Levy = df_test.Levy.astype(int)\n",
    "df_test.loc[df_test.Cylinders > 15, 'Cylinders'] = 15\n",
    "\n",
    "df_test.loc[~df_test.Manufacturer.isin(top_manufacturers), 'Manufacturer'] = 'Other'\n",
    "df_dummies_test = pd.get_dummies(df_test[cat_cols], drop_first=True)\n",
    "\n",
    "#############################################\n",
    "\n",
    "X_submit = pd.concat([df_test[num_cols], df_dummies_test], axis=1)\n",
    "X_submit_scaled = pd.DataFrame(scaler.transform(X_submit), columns=X_cols)\n",
    "X_submit_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 2))\n",
    "plt.subplot(121); sns.histplot(df_train.Airbags)\n",
    "plt.subplot(122); sns.histplot(df_test.Airbags)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 2))\n",
    "plt.subplot(121); sns.boxplot(X_train.Mileage)\n",
    "plt.subplot(122); sns.boxplot(X_submit.Mileage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 2))\n",
    "plt.subplot(121); sns.histplot(X_train.Levy)\n",
    "plt.subplot(122); sns.histplot(X_submit.Levy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4))\n",
    "for col in num_cols:\n",
    "    plt.subplot(1, len(num_cols), num_cols.index(col)+1)\n",
    "    sns.boxplot(df_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = pd.DataFrame(np.round(np.exp(rf_model.predict(X_submit_scaled)), 2) , columns=['Price'])\n",
    "y_submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_submit = pd.DataFrame(np.round(np.exp(rf_tuned.predict(X_submit_scaled)), 2) , columns=['Price'])\n",
    "y_submit.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
